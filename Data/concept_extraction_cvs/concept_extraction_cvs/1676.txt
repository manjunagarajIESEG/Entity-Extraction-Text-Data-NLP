Technical Architect
Capital One
USA Capital One is diversified bank that offer a broad array of financial products and services to consumer, small business and commercial clients. Capital One has one of the most widely recognized brand in America. As one of the Nation's top 10 largest banks based on deposit and transaction. Objective of the Project was convert all its data sources to Hadoop platforms to perform future analytics. ROLE: Technical Architect. Responsibilities: • Architected, designed and implemented Apache Sentry Application for Database Security • Participated in review, requirement gathering and creating SRS and high level requirements • Organized meetings with business users, architects and operations teams to gather business requirements and implemented the solutions. • Participate in and drive cross-functional, cross discipline architecture teams to enhance/set the architectural direction for key business initiatives. • Serve as a fully seasoned/proficient technical resource; routine accountability for technical knowledge and capabilities as a team member and as an individual contributor. • Identify technical solutions to business problems and drive to resolution. • Designed and created a Spark-Python Script that generates Metadata Comparison report used by the Data Guardians for compliance check of datasets. • Lead and facilitated development team in developing DQ Framework which was used by various teams to verify the Schema of the files. • Working closely with Cloudera team in implementing Apache Record Service application which will enable users to use Hive Views in Spark and MapReduce • One of the key contributors for converting code from EDCDIC format to ASCII format utilizing MapReduce • Implemented Apache Navigator application to monitor the Data Lineage and auditing. • Work with business partners to translate functional requirements into technical requirements. • Splitting to shared dataset into NPI, Credit and Anonymous classifications as per federal regulations through a PIG Script where the schema of the split is passed as a parameter  Environment: Apache Spark, PIG, Hive, Impala, MapReduce, Apache Sentry, Apache Navigator, Cloudera Hue, Cloudera Record Service, Python, Java
