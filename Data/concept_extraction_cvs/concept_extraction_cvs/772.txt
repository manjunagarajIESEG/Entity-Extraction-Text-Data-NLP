Data Analytics Engineer
Nokia - Burlington, MA
• Developed MR code in java to analyze Assisted-GPS (aGPS) telemetry data originating from Nokia mobile phones.  Developed necessary Hadoop ETLs to read and re-format binary structured data on an hourly ingestion schedule.  Streamlined ETL throughput and storage using Protocol Buffers with LZO compression.  Created additional aggregation MR ETLs to satisfy individual statistical use cases. Partitioned data for Hive to enable adhoc queries across all raw and derived aGPS data subsets.  Developed support processing ETLs for dimension table updates in HDFS and Oracle. Developed scripts to push HDFS data to Oracle for Tableau visualization.  The new data sets enabled engineers to view hourly aGPS statistics in addition to performing adhoc queries on raw data using Hive and pig.  The visualizations and data access permitted engineers to peer into the system and ask new questions.  Results were presented during in-house data analytics expo and yearly project highlights town hall meeting. • Assisted Insights group by performing data cleansing exercises by providing specific chronological normalized data-sets using Hadoop streams written in Python or Perl.  Worked on several small project that used Pig scripts to provide daily ingestion feeds of aggregates to a Business units' visualization engine. • Developed several tool-sets to help configure and launch EMR jobs and EC2 instances using AWS SDK. • Contributed to developing an in-house data-driven ETL framework for AWS EMR, for replacing our corporate Hadoop cluster.  Extension of mapper would use configuration data instead to define and drive a complete data flow. • Integrated Nokia's Data Asset Catalog database to the improved ETL framework by developing a Jena hosted RDF ontology which fully described a job processing pipeline; i.e. the recipe of how to derive any Nokia data-set in RDF. as a DAG of inputs, processing nodes, and outputs.  Abstraction allowed rendering job flow as a sequence of steps in HD/MR or as a Storm graph of bolts and subscription edges. Graphviz libraries were used to produce a runtime visualization of the job.  Experimented with Protégé as an RDF modeling tool, used a local Fuseki server for SPARQL query and ontology development.
